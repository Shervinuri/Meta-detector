# <p align="center">SHΞN™ Meta Finder 👁️‍🗨️</p>
<p align="center">
  <a href="https://googleify.netlify.app/" target="_blank"><img src="https://img.shields.io/badge/Status-Live%20Demo-brightgreen?style=for-the-badge" alt="Live Demo" /></a>
  <img src="https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB" alt="React" />
  <img src="https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white" alt="TypeScript" />
  <img src="https://img.shields.io/badge/Google%20Gemini-4285F4?style=for-the-badge&logo=google&logoColor=white" alt="Gemini API" />
  <img src="https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white" alt="Tailwind CSS" />
</p>

<h3 align="center">یک دستیار متخصص همه‌جانبه با دید اول شخص (POV) - پلتفرم پایه برای اپلیکیشن‌های عینک هوشمند</h3>

---

## 🎯 **مفهوم اصلی: تبدیل تلفن همراه به عینک هوشمند**

**SHΞN™ Meta Finder** یک وب اپلیکیشن پیشرفته است که تلفن همراه شما را به یک دستیار متخصص و قدرتمند تبدیل می‌کند و قابلیت‌های کلیدی عینک‌های هوشمند پیشرفته مانند **عینک گوگل (Google Glass)** یا **عینک متا (Meta Quest)** را شبیه‌سازی می‌کند.

این برنامه با بهره‌گیری از دوربین و میکروفون دستگاه، یک تجربه یکپارچه از دید اول شخص (Point-of-View) فراهم می‌کند که در آن کاربر می‌تواند با محیط اطراف خود تعامل داشته باشد و از طریق یک هوش مصنوعی مکالمه‌محور، راهنمایی‌های هوشمند و فوری دریافت کند. هوش مصنوعی آنچه شما می‌بینید را می‌بیند، آنچه شما می‌گویید را می‌شنود و به صورت زنده به شما کمک می‌کند.

> این پروژه به عنوان یک پلتفرم بنیادی برای ساخت نسل جدیدی از اپلیکیشن‌های واقعیت افزوده و دستیار زنده عمل می‌کند.

## ✨ **قابلیت‌های کلیدی**

- **👁️ تحلیل زنده فید ویدیو:** هوش مصنوعی یک جریان پیوسته از دوربین را برای درک محیط کاربر پردازش می‌کند.
- **🎙️ هوش مصنوعی مکالمه‌محور:** جریان صوتی دوطرفه با تأخیر کم، امکان مکالمات طبیعی و روان با دستیار هوش مصنوعی را فراهم می‌کند.
- **🧠 تشخیص هوشمند اشیاء و برندها:** مدل می‌تواند اشیاء، قطعات خاص و حتی لوگوی برندها را بر اساس درخواست کاربر شناسایی کند.
- **👆 کادرهای مرزی تعاملی:** هوش مصنوعی می‌تواند کادرهایی را دور اشیاء شناسایی‌شده مستقیماً روی صفحه بکشد تا توجه کاربر را جلب کند.
- **🌐 یکپارچه‌سازی با جستجوی وب:** برای سؤالاتی که نیاز به اطلاعات به‌روز دارند (مانند قیمت، اخبار، مشخصات فنی)، هوش مصنوعی از جستجوی گوگل برای ارائه پاسخ‌های دقیق و معتبر استفاده می‌کند.
- **🦾 عملکرد مبتنی بر ابزار:** هوش مصنوعی می‌تواند از توابع از پیش تعریف‌شده (`displayDetectedObjects`, `clearDetectedObjects`) برای تعامل با رابط کاربری استفاده کند و یک تجربه واقعاً پویا ایجاد نماید.

## 🚀 **کاربردهای بالقوه و چشم‌انداز آینده**

این پلتفرم فقط یک دمو نیست؛ بلکه یک سکوی پرتاب برای طیف گسترده‌ای از اپلیکیشن‌های انقلابی است. این پتانسیل‌ها را تصور کنید:

### 🛠️ **راهنمای زنده فنی و تعمیرات**
- **تعمیرات خودرو:** کاربر دوربین خود را به سمت موتور خودرو می‌گیرد و می‌پرسد: «مخزن ضدیخ کجاست؟» هوش مصنوعی آن را هایلایت کرده و دستورالعمل‌های گام‌به‌گام برای پر کردن آن را ارائه می‌دهد.
- **عیب‌یابی الکترونیک:** راهنمایی کاربر در تشخیص و تعمیر یک برد مدار، شناسایی قطعات و نشان دادن نقاط تست.
- **تعمیر لوازم خانگی:** کمک به یک کاربر برای تعمیر ماشین لباسشویی، از شناسایی کد خطا تا تعویض یک قطعه معیوب.

### ❤️ **کمک‌های اولیه و اورژانس**
- **واکنش در سوانح:** در یک موقعیت بحرانی، هوش مصنوعی می‌تواند بر اساس آنچه از طریق دوربین کاربر می‌بیند، راهنمایی‌های فوری و بدون نیاز به دست برای بستن شریان‌بند، انجام CPR یا درمان سوختگی ارائه دهد.
- **مشاوره پزشکی از راه دور:** یک امدادگر در میدان می‌تواند دید اول شخص خود را برای یک پزشک از راه دور استریم کند تا در موارد پیچیده مشاوره تخصصی دریافت نماید.

### 🎓 **آموزش و یادگیری**
- **آموزش حین کار:** یک تکنسین جدید می‌تواند نحوه کار با ماشین‌آلات پیچیده را با راهنمایی‌های زنده و هشدارهای ایمنی از هوش مصنوعی یاد بگیرد.
- **یادگیری تعاملی:** یک دانشجو که در حال یادگیری گیاه‌شناسی است، می‌تواند دوربین خود را به سمت یک گیاه بگیرد و هوش مصنوعی آن را شناسایی کرده و اطلاعات دقیقی ارائه دهد.

---

## ⚙️ **راهنمای راه‌اندازی و استفاده**

برای اجرای این پروژه به صورت عمومی یا در محیط توسعه خود، مراحل زیر را دنبال کنید:

1.  **مشاهده نسخه زنده:**
    *   برای تجربه سریع و مستقیم، می‌توانید به نسخه دیپلوی شده در آدرس زیر مراجعه کنید:
    *   **[https://googleify.netlify.app](https://googleify.netlify.app)**

2.  **دریافت کلید API:**
    *   این پروژه از Google Gemini API استفاده می‌کند. شما به یک کلید API نیاز دارید.
    *   به وبسایت **[Google AI Studio](https://aistudio.google.com/app/apikey)** بروید.
    *   یک کلید API جدید بسازید و آن را کپی کنید.

3.  **وارد کردن کلید API:**
    *   هنگام باز کردن برنامه برای اولین بار، یک پنجره از شما می‌خواهد که کلید API خود را وارد کنید.
    *   کلید کپی شده را در فیلد مربوطه قرار داده و دکمه "ذخیره و ادامه" را بزنید.
    *   *نکته: کلید شما فقط در مرورگر شما ذخیره می‌شود و به هیچ سروری ارسال نمی‌گردد.*

4.  **اعطای دسترسی‌ها:**
    *   مرورگر از شما برای دسترسی به **دوربین** و **میکروفون** اجازه می‌خواهد. برای عملکرد صحیح برنامه، این دسترسی‌ها را **Allow (اجازه دادن)** کنید.

5.  **شروع تعامل:**
    *   پس از بارگذاری کامل، روی دکمه بزرگ **میکروفون** در پایین صفحه کلیک کنید تا جلسه زنده آغاز شود.
    *   حالا می‌توانید با هوش مصنوعی صحبت کنید. دوربین را به سمت اشیاء مورد نظر بگیرید و سوالات خود را بپرسید.

#### **💡 مثال‌هایی برای امتحان کردن:**
- دوربین را به سمت یک شیء بگیرید و بپرسید: *"این چیه؟"*
- برای پیدا کردن یک قطعه خاص در موتور ماشین بگویید: *"مخزن روغن ترمز کجاست؟"* (هوش مصنوعی یک کادر دور آن می‌کشد)
- برای حذف کادرها بگویید: *"حالا کادر رو پاک کن"*
- برای اطلاعات به‌روز بپرسید: *"قیمت جدیدترین مدل این گوشی چنده؟"*

---

## 💻 **پشته فناوری (Technology Stack)**

- **فرانت‌اند:** `React`, `TypeScript`, `Tailwind CSS`
- **هوش مصنوعی:** `Google Gemini API` (به‌طور خاص مدل `gemini-2.5-flash-native-audio-preview-09-2025` برای Live API)
- **API‌های وب:** `WebRTC (getUserMedia)`, `Web Audio API`

---

<p align="center">
  <a href="https://T.me/shervini" target="_blank" rel="noopener noreferrer">
    <strong>Exclusive SHΞN™ made</strong>
  </a>
</p>
